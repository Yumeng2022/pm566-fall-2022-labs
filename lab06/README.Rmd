---
title: "Lab 06"
author: "Yumeng Gao"
date: "`r Sys.Date()`"
output: github_document
always_allow_html: true
---

```{r}
library(webshot)
webshot::install_phantomjs()
```

```{r install-libraries}
library(R.utils)
library(lubridate)
library(tidyverse)
library(tidytext)
library(dplyr)
library(dtplyr)
library(data.table)
library(tidyr)
library(ggplot2)
library(forcats)
```

## Read in the data
First download and then read in csv.
```{r read-data, cache= TRUE}
if (!file.exists("mtsamples.csv")) {
  download.file(
    url = "https://raw.githubusercontent.com/USCbiostats/data-science-data/master/00_mtsamples/mtsamples.csv",
    "mtsamples.csv", method = "libcurl", timeout  = 60)
}
mts <- read.csv("mtsamples.csv")
str(mts)
mts= as_tibble(mts)
mts
```

## Question 1: What specialties do we have?
We can use count() from dplyr to figure out how many records are there per specialty? 
```{r mdeical_specialties}
specialties=
  mts %>%
  count(medical_specialty)

specialties %>%
  arrange(desc(n)) %>%
knitr::kable()
```

There are `r nrow(specialties)` medical specialties.

```{r barplot-of-specialty-counts}
specialties %>%
  top_n(10) %>%
  ggplot( aes(x= n, y= fct_reorder(medical_specialty, n))) +
  geom_col()
```

The distribution is not at all uniform.

## Question 2: Visualize the top 20 most frequent words in the transcription column

* Tokenize the the words in the transcription column
* Count the number of times each token appears
* Visualize the top 20 most frequent words

```{r token-transcription, cache=TRUE}
mts %>%
  unnest_tokens(word, transcription) %>%
  #anti_join(stop_words, by = c("word")) %>%
  count(word, sort = TRUE) %>%
  top_n(20, n) %>%
  ggplot(aes(n, fct_reorder(word, n))) +
  geom_col()
```

There are a lot of stop words here, non-specific to medical text,
We do see "patient".

## Question 3: Redo analysis in Q2, amd remove stopwords
* Redo visualization but remove stopwords before
* Bonus points if you remove numbers as well

```{r, cache=TRUE}
mts %>%
  unnest_tokens(word, transcription) %>%
  count(word, sort = TRUE) %>%
  anti_join(stop_words, by = c("word")) %>%
  # use regular expression to filter out numbers (not match 0-9)
  filter( !grepl(pattern= "^[0-9]+$", x= word)) %>%
  top_n(20, n) %>%
  ggplot(aes(n, fct_reorder(word, n))) +
  geom_col()
```

It give us a much better idea of what the text is about after getting rid of the stopwords and numbers.

## Question 4
repeat question 2, but this time tokenize into bi-grams. 
how does the result change if you look at tri-grams?


```{r bigrams-transcription, cache=TRUE}
mts %>%
  unnest_ngrams(bigram, transcription, n=2) %>%
  count(bigram, sort = TRUE) %>%
  top_n(20, n) %>%
  ggplot(aes(n, fct_reorder(bigram, n))) +
  geom_col()
```

```{r trigrams-transcription, cache=TRUE}
mts %>%
  unnest_ngrams(trigram, transcription, n=3) %>%
  count(trigram, sort = TRUE) %>%
  top_n(20, n) %>%
  ggplot(aes(n, fct_reorder(trigram, n))) +
  geom_col()
```

Top 20 trigrams seemed to find a few more medical word group than bigrams.

## Question 5
Using the results you got from questions 4. Pick a word and count the words that appears after and before it.

```{r bigrams-transcription-nextword, cache=TRUE}
ptbigram =
  mts %>%
  unnest_ngrams(bigram, transcription, n=2) %>%
  separate(bigram, into = c("word1", "word2"), sep = " ") %>%
  select(word1, word2) %>%
  filter(word1 == "patient" | word2 == "patient")
```

Words appearing before patient:

```{r before-patient} 
ptbigram %>%
  filter(word2 == "patient") %>%
  count(word1, sort=T) %>%
  anti_join(stop_words, by= c("word1"= "word")) %>%
  top_n(10) %>%
knitr::kable()
```

Words appearing after patient:

```{r after-patient} 
ptbigram %>%
  filter(word1 == "patient") %>%
  count(word2, sort=T) %>%
  anti_join(stop_words, by= c("word2"= "word")) %>%
  top_n(10) %>%
knitr::kable()
```

## Question 6
Which words are most used in each of the specialties. you can use group_by() and top_n() from dplyr to have the calculations be done within each specialty. 
Remember to remove stopwords. How about the most 5 used words?
```{r}
mts %>%
  unnest_tokens(word, transcription) %>%
  group_by(medical_specialty) %>%
  count(word) %>%
  filter(!(word %in% stop_words$word) & !grepl(pattern= "^[0-9]+$", x= word)) %>%
  top_n(5, n) %>%
  arrange(medical_specialty, desc(n)) %>%
knitr::kable()
```



